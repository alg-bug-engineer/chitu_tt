# SPDX-FileCopyrightText: 2025 Qingcheng.AI
#
# SPDX-License-Identifier: Apache-2.0

# Llama-3-8B-QServe-g128 is a quantization of Meta-Llama-3-8B-Instruct
defaults:
  - Meta-Llama-3-8B-Instruct
  - quant_config: w4a8_per_token_per_group_asymm
  - _self_ # Config in this file overrides configs in defaults

# Access info
name: Llama-3-8B-QServe-g128
source: "https://huggingface.co/mit-han-lab/Llama-3-8B-QServe-g128" # Just for displaying. No automatic download.
ckpt_dir: null # Please override this in commond line with `models.ckpt_dir=<path>`.
tokenizer_path: null # By default the same as ckpt_dir, or you can override it with `models.tokenizer_path=<path>`.
